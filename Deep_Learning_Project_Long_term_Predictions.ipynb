{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimitrisReppas/Analysis-and-prediction-of-stock-prices/blob/main/Deep_Learning_Project_Long_term_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkIwFjDF1i8G"
      },
      "source": [
        "# Deep Learning Project: Predicting for multiple days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK9rugKk4FAN"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PUnwB3P4Gbg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, Bidirectional, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.metrics import MeanAbsolutePercentageError, MeanSquaredError, Accuracy, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBRegressor "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBom6uRfymgR"
      },
      "source": [
        "### Auxilary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsR2HLxkwOw2"
      },
      "source": [
        "def write_values(rects, ax):\n",
        "  heights = [r.get_height() for r in rects]\n",
        "  rel_heights = [h/max(heights) for h in heights]\n",
        "  idx = heights.index(max(heights))\n",
        "  for i,(r,h, rh) in enumerate(zip(rects, heights, rel_heights)):\n",
        "      ax.text(r.get_x() + r.get_width()/2.0, h + max(heights) * .01, f'{h:.2}', ha='center')\n",
        "\n",
        "def factor_int(n):\n",
        "  val = math.ceil(math.sqrt(n))\n",
        "  val2 = int(n/val)\n",
        "  while val2 * val != float(n):\n",
        "    val -= 1\n",
        "    val2 = int(n/val)\n",
        "  return val, val2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLCNSKez3WMF"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYFbjKzL3X_u"
      },
      "source": [
        "!gdown --id 1TS-Jluy0_40MkIJkF9wUP1Xih6e1M35p\n",
        "!unzip cac40.zip -d cac40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDFbe2fO3vcx"
      },
      "source": [
        "cac40 = pd.read_csv('/content/cac40/preprocessed_CAC40.csv', \n",
        "                   usecols = ['Name','Date','Open','Closing_Price','Daily_High','Daily_Low','Volume']\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMu9yiDzeHiX"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUWkkyxtmCUD"
      },
      "source": [
        "#Stock name encoder\n",
        "name_encoder = OrdinalEncoder()\n",
        "#Value scaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "feature_cols = [\n",
        "                # 'Movement',\n",
        "                'Closing_Price', \n",
        "                # 'Open', 'Daily_High', 'Daily_Low', \"Volume\", \n",
        "                # 'avg',\n",
        "                # \"ma7\", \"ma21\", \"ema26\", \"ema12\", \"MACD\", \"upper_band\", \"lower_band\", \"ema\", \"momentum\",\n",
        "                \"Year\", \"Month\", \"Day\", \"Day of Week\", \"Name\"]\n",
        "\n",
        "def create_timeseries(data, lag):\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for i in range(lag, len(data)):\n",
        "      x.append(data[i - lag:i, :])\n",
        "      y.append(data[i, 0])\n",
        "  \n",
        "  x, y = np.array(x), np.array(y)\n",
        "  x = np.reshape(x, (x.shape[0], x.shape[1], -1))\n",
        "\n",
        "  assert len(x) == len(y)\n",
        "  return x, y\n",
        "\n",
        "def create_lag_features(data, lag):\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for i in range(lag, len(data)):\n",
        "      x.append(data[i - lag:i, :])\n",
        "      y.append(data[i, 0])\n",
        "  \n",
        "  x, y = np.array(x), np.array(y)\n",
        "  x = np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "  assert len(x) == len(y)\n",
        "  return x, y\n",
        "\n",
        "def create_dataset(df, lag=60, dataset_format='timeseries', stock=None, target=\"regression\"):\n",
        "  if stock:\n",
        "    #Keep only one specific stock\n",
        "    X = df[df['Name'] == stock].copy()\n",
        "  else:\n",
        "    #Keep all stocks\n",
        "    X = df.copy()\n",
        "\n",
        "\n",
        "  #Sort data from oldest to newest\n",
        "  X = X.sort_values('Date')\n",
        "  \n",
        "  #Convert name from string to int\n",
        "  X['Name'] = name_encoder.fit_transform(X['Name'].to_numpy().reshape(-1,1))\n",
        "\n",
        "  #Convert volume from string to float\n",
        "  X['Volume'].str.strip()\n",
        "  X['Volume'] = X['Volume'].replace(',','', regex=True)\n",
        "  X['Volume'] = X['Volume'].astype('float')\n",
        "\n",
        "  #Replace NaN values\n",
        "  for name, values in X.iteritems():\n",
        "    if values.isnull().sum() > 0:\n",
        "      X[name].interpolate(inplace=True)\n",
        "  assert X.isnull().sum().sum() == 0\n",
        "\n",
        "  #Create additional features and technical indicators\n",
        "  #Average of given prices\n",
        "  X['avg'] = X[['Closing_Price', 'Open', 'Daily_High', 'Daily_Low']].mean().mean()\n",
        "  # Create 7 and 21 days Moving Average\n",
        "  X['ma7'] = X['Closing_Price'].rolling(window = 7).mean()\n",
        "  X['ma21'] = X['Closing_Price'].rolling(window = 21).mean()\n",
        "  #Create MACD\n",
        "  X['ema26'] = X['Closing_Price'].ewm(span=26).mean()\n",
        "  X['ema12'] = X['Closing_Price'].ewm(span=12).mean()\n",
        "  X['MACD'] = (X['ema12']-X['ema26'])\n",
        "  #Create Bollinger Bands\n",
        "  X['20sd'] = X['Closing_Price'].rolling(window = 20).std()\n",
        "  X['upper_band'] = (X['Closing_Price'].rolling(window = 20).mean()) + (X['20sd']*2)\n",
        "  X['lower_band'] = (X['Closing_Price'].rolling(window = 20).mean()) - (X['20sd']*2)\n",
        "  #Create Exponential moving average\n",
        "  X['ema'] = X['Closing_Price'].ewm(com=0.5).mean()\n",
        "  #Create Momentum\n",
        "  X['momentum'] = X['Closing_Price'].rolling(window=10).apply(lambda x: x.iat[-1] - x.iat[0])\n",
        "\n",
        "  #Replace NaN values\n",
        "  for name, values in X.iteritems():\n",
        "    if values.isnull().sum() > 0:\n",
        "      X[name].interpolate(inplace=True, limit_direction='both')\n",
        "  assert X.isnull().sum().sum() == 0\n",
        "\n",
        "  #Break day into year, month, day and day of week (e.g. Monday, etc.)\n",
        "  X['Date'] = pd.to_datetime(X['Date'])\n",
        "  X['Year'] = X['Date'].dt.year\n",
        "  X['Month'] = X['Date'].dt.month\n",
        "  X['Day'] = X['Date'].dt.day\n",
        "  X['Day of Week'] = X['Date'].dt.dayofweek\n",
        "\n",
        "  #Throw away original date column\n",
        "  X = X.drop(columns=['Date'])\n",
        "  year = X['Year']\n",
        "\n",
        "  #Move target column to first column\n",
        "  if target == 'regression':\n",
        "    close = X.pop(\"Closing_Price\")\n",
        "    X.insert(0, \"Closing_Price\", close)\n",
        "  elif target == 'classification':\n",
        "    X['Movement'] = X['Closing_Price'].rolling(window=2).apply(lambda x: 1 if x.iat[-1] > x.iat[0] else 0)\n",
        "    X['Movement'].iat[0] = 0\n",
        "    movement = X.pop(\"Movement\")\n",
        "    X.insert(0, \"Movement\", movement)\n",
        "  else:\n",
        "    raise ValueError()\n",
        "\n",
        "  #Keep only necessary features\n",
        "  X = pd.DataFrame(X, columns=feature_cols)\n",
        "\n",
        "  # Normalize data\n",
        "  if scaler != None:\n",
        "    X = scaler.fit_transform(X)\n",
        "  else:\n",
        "    X = X.to_numpy()\n",
        "\n",
        "  #Split into train, test\n",
        "  train_points = year < 2019\n",
        "  train_data = X[train_points]\n",
        "  \n",
        "  test_points = year >= 2019\n",
        "  test_points.iloc[test_points.argmax()-lag:] = True\n",
        "  test_data = X[test_points]\n",
        "\n",
        "  if dataset_format == 'timeseries':\n",
        "    X_train, y_train = create_timeseries(train_data, lag)\n",
        "    X_test, y_test = create_timeseries(test_data, lag)\n",
        "  elif dataset_format == 'lag_features':\n",
        "    X_train, y_train = create_lag_features(train_data, lag)\n",
        "    X_test, y_test = create_lag_features(test_data, lag)\n",
        "\n",
        "  return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "\n",
        "def next_day(row):\n",
        "  year, month, day = round(row['Year'].item()), round(row['Month'].item()), round(row['Day'].item())\n",
        "  new_date = pd.Timestamp(year=year, month=month, day=day)\n",
        "  new_date += pd.Timedelta(days=3 if int(row['Day of Week'].item()) == 4 else 1)\n",
        "  return new_date\n",
        "\n",
        "def dataset_to_df(X, Y, lag=60):\n",
        "  if X.ndim == 3:\n",
        "    last_days = X[:, -1, :]\n",
        "  elif X.ndim == 2:\n",
        "    n_feat = int(X.shape[1]/lag)\n",
        "    last_days = X[:, -n_feat:]\n",
        "  new_df = pd.DataFrame(last_days, columns=feature_cols)\n",
        "  #Replace closing price with y and scale back to original values\n",
        "  new_df['Closing_Price'] = Y\n",
        "  if scaler != None:\n",
        "    new_df = pd.DataFrame(scaler.inverse_transform(new_df), columns=feature_cols)\n",
        "  #Go to next day (i.e. day of the prediction)\n",
        "  new_df['Date'] = new_df.apply(next_day, axis=1)\n",
        "  #Convert name to string\n",
        "  new_df[\"Name\"] = name_encoder.inverse_transform(new_df[\"Name\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "  return pd.DataFrame(new_df, columns=['Name', \"Date\", \"Closing_Price\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2kaxF0ffGHv"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = create_dataset(cac40, stock=\"TOTAL\")\n",
        "# (X_train, y_train), (X_test, y_test) = create_dataset(cac40)\n",
        "# (X_train, y_train), (X_test, y_test) = create_dataset(cac40, dataset_format=\"lag_features\", stock=\"TOTAL\")\n",
        "# (X_train, y_train), (X_test, y_test) = create_dataset(cac40, stock=\"TOTAL\", dataset_format=\"lag_features\", target=\"classification\")\n",
        "\n",
        "print(f\"X_train: {str(X_train.shape):14}, y_train: {y_train.shape}\")\n",
        "print(f\"X_test:  {str(X_test.shape):14}, y_test:   {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goIH_9KT49Gs"
      },
      "source": [
        "train_df = dataset_to_df(X_train, y_train)\n",
        "test_df = dataset_to_df(X_test, y_test)\n",
        "\n",
        "# Line plot\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "plt.plot(train_df['Date'], train_df['Closing_Price'], label=\"Train\")\n",
        "plt.plot(test_df['Date'], test_df['Closing_Price'], label=\"Test\")\n",
        "\n",
        "# Formatting\n",
        "ax.set_title('Closing Price', fontsize = 20, loc='center', fontdict=dict(weight='bold'))\n",
        "ax.set_xlabel('Year', fontsize = 16, fontdict=dict(weight='bold'))\n",
        "ax.set_ylabel('Price', fontsize = 16, fontdict=dict(weight='bold'))\n",
        "ax.legend()\n",
        "plt.tick_params(axis='y', which='major', labelsize=16)\n",
        "plt.tick_params(axis='x', which='major', labelsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwtSvTNi3j4b"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi5EiLBooCes"
      },
      "source": [
        "### Define Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uhXwY7A4AF_"
      },
      "source": [
        "def BiLSTM_model(inp_shape):\n",
        "  model = Sequential()\n",
        "  model.add(Bidirectional(LSTM(32, input_shape=(inp_shape), return_sequences = True)))\n",
        "  model.add(Bidirectional(LSTM(16)))\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  return model\n",
        "\n",
        "def BiGRU_model(inp_shape):\n",
        "  model = Sequential()\n",
        "  model.add(Bidirectional(GRU(32, input_shape=(inp_shape), return_sequences = True)))\n",
        "  model.add(Bidirectional(GRU(16)))\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('relu'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rkQjSTgoLu3"
      },
      "source": [
        "### Train and Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUYunqcqX9gA"
      },
      "source": [
        "results = {}\n",
        "PRED_DAYS = 60\n",
        "LAG = 30\n",
        "STOCK = \"Accor\"\n",
        "CREATE_FUNC = BiLSTM_model\n",
        "\n",
        "feature_cols = [\n",
        "                'Closing_Price', \n",
        "                \"Year\", \"Month\", \"Day\", \"Day of Week\", \"Name\"\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o3XQmki4EUp"
      },
      "source": [
        "model_create_funcs = {\n",
        "    \"Bi-LSTM\" : (BiLSTM_model, \"timeseries\"),\n",
        "    \"Bi-GRU\" : (BiGRU_model, \"timeseries\"),\n",
        "}\n",
        "\n",
        "for name, (create_func, dataset_format) in model_create_funcs.items():  \n",
        "  #Create dataset\n",
        "  (X_train, y_train), (X_test, y_test) = create_dataset(cac40, lag=LAG, dataset_format=dataset_format, stock=STOCK, target=\"regression\")\n",
        "  #Create model\n",
        "  if X_train.ndim == 3:\n",
        "    model = create_func((X_train.shape[1], X_train.shape[2]))\n",
        "  elif X_train.ndim == 2:\n",
        "    model = create_func((X_train.shape[1],))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "  #Define callbacks\n",
        "  early_stopper = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "  cbs = [early_stopper]\n",
        "\n",
        "  #Train model\n",
        "  model.fit(X_train, y_train, validation_split=0.1, epochs=40, batch_size=1, verbose=1, callbacks=cbs)\n",
        "\n",
        "  #Make predictions on test set\n",
        "  X_test = X_test[:PRED_DAYS, :, :]\n",
        "  y_test = y_test[:PRED_DAYS]\n",
        "  X_pred = X_test.copy()\n",
        "  predicted_prices = [ ]\n",
        "\n",
        "  for i in tqdm(range(PRED_DAYS)):\n",
        "    pred = model.predict(X_pred[[i], :, :])\n",
        "    pred = pred[0][0]\n",
        "\n",
        "    predicted_prices.append(pred)\n",
        "\n",
        "    if i + 1 < PRED_DAYS:\n",
        "      X_pred[i+1, :len(predicted_prices[-LAG:]), 0] = np.array(predicted_prices[-LAG:])\n",
        "\n",
        "  #Convert predictions\n",
        "  pred_df = dataset_to_df(X_test, predicted_prices, lag=LAG)\n",
        "  #Get metrics on test set\n",
        "  mse = MeanSquaredError()(predicted_prices, y_test)\n",
        "  mape = MeanAbsolutePercentageError()(predicted_prices, y_test) \n",
        "  #Make predictions on train set\n",
        "  predicted_prices = model.predict(X_train)\n",
        "  #Get metrics on train set\n",
        "  train_mse = MeanSquaredError()(predicted_prices, y_train)\n",
        "  train_mape = MeanAbsolutePercentageError()(predicted_prices, y_train)\n",
        "\n",
        "  results[name] = {\n",
        "      \"pred\" : pred_df,\n",
        "      \"mse\" : mse,\n",
        "      \"mape\" : mape,\n",
        "      \"train_mse\" : mse,\n",
        "      \"train_mape\" : mape\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TzZdd8L-B7G"
      },
      "source": [
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5QKnpLM8_lO"
      },
      "source": [
        "#Line Plot\n",
        "ncols, nrows = factor_int(len(results))\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(9*ncols, 3*nrows), sharex=True, sharey=True)\n",
        "\n",
        "#Get actual prices\n",
        "real_df = dataset_to_df(X_test, y_test, lag=LAG)\n",
        "if STOCK != None:\n",
        "  real_df = real_df[real_df[\"Name\"] == STOCK]\n",
        "\n",
        "for (name, res), ax in zip(results.items(), axes.flatten()):\n",
        "  #Plot predictions\n",
        "  pred_df = results[name]['pred']\n",
        "  if STOCK != None:\n",
        "    pred_df = pred_df[real_df[\"Name\"] == STOCK]\n",
        "  ax.plot(pred_df['Date'], pred_df['Closing_Price'], label=f\"{name} predicted price\")\n",
        "  #Plot actual prices\n",
        "  ax.plot(real_df['Date'], real_df['Closing_Price'], label=\"Actual price\")\n",
        "  #Plot formatting\n",
        "  ax.legend()\n",
        "  ax.set_ylabel('Price', fontsize = 9)\n",
        "\n",
        "#Figure Formatting\n",
        "fig.suptitle(f'Predicted prices for the {STOCK} stock', fontsize = 20, fontdict=dict(weight='bold'))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W3OwAHp-UMk"
      },
      "source": [
        "methods = []\n",
        "mse_scores = []\n",
        "mape_scores = []\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'orange', 'pink', 'yellow', 'purple', 'cyan']\n",
        "\n",
        "for name, res in results.items():\n",
        "  #Plot scores\n",
        "  methods.append(name)\n",
        "  mse_scores.append(results[name]['mse'])\n",
        "  mape_scores.append(results[name]['mape'])\n",
        "  \n",
        "\n",
        "#Bar Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "x = np.arange(len(results)) + 0.3\n",
        "bar_width = 0.4\n",
        "\n",
        "rects = ax1.bar(x, mse_scores, bar_width, color=colors)\n",
        "write_values(rects, ax1)\n",
        "\n",
        "rects = ax2.bar(x, mape_scores, bar_width, color=colors)\n",
        "write_values(rects, ax2)\n",
        "\n",
        "#Plot Formatting\n",
        "ax1.set_title('Mean Square Error (MSE)', fontsize = 18, loc='center')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(results.keys())\n",
        "\n",
        "ax2.set_title('Mean Absolute Percentage Error (MAPE)', fontsize = 18, loc='center')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(results.keys())\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}